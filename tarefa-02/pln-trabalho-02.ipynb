{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"109u-bWYiUB6LLNB34HgR6T0I7jBC9Obf","timestamp":1702403046823}],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["Grupo:\n","Arthur /\n","Fabiano /\n","Mateus"],"metadata":{"id":"4pbvcCqfvv0p"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"nKhTfZUM7i21","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702403127696,"user_tz":180,"elapsed":63923,"user":{"displayName":"Mateus Merçon","userId":"05028490932371476290"}},"outputId":"711c13dc-8c5a-430f-fe7a-e720ac7471ec"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n","Collecting pip\n","  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: pip\n","  Attempting uninstall: pip\n","    Found existing installation: pip 23.1.2\n","    Uninstalling pip-23.1.2:\n","      Successfully uninstalled pip-23.1.2\n","Successfully installed pip-23.3.1\n","Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=b3a33fd2ecc7aaf1f8bb9b7e7fd345bb226d1f6c387f3e3037083875cb6a599a\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting sklearn_crfsuite\n","  Downloading sklearn_crfsuite-0.3.6-py2.py3-none-any.whl (12 kB)\n","Collecting python-crfsuite>=0.8.3 (from sklearn_crfsuite)\n","  Downloading python_crfsuite-0.9.9-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (993 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m993.5/993.5 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (1.16.0)\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (0.9.0)\n","Requirement already satisfied: tqdm>=2.0 in /usr/local/lib/python3.10/dist-packages (from sklearn_crfsuite) (4.66.1)\n","Installing collected packages: python-crfsuite, sklearn_crfsuite\n","Successfully installed python-crfsuite-0.9.9 sklearn_crfsuite-0.3.6\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0mCollecting scikit-learn==1.3.2\n","  Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n","Requirement already satisfied: numpy<2.0,>=1.17.3 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2) (1.23.5)\n","Requirement already satisfied: scipy>=1.5.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn==1.3.2) (3.2.0)\n","Downloading scikit_learn-1.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: scikit-learn\n","  Attempting uninstall: scikit-learn\n","    Found existing installation: scikit-learn 1.2.2\n","    Uninstalling scikit-learn-1.2.2:\n","      Successfully uninstalled scikit-learn-1.2.2\n","Successfully installed scikit-learn-1.3.2\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m2023-12-12 17:45:11.742930: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n","2023-12-12 17:45:11.743000: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n","2023-12-12 17:45:11.743037: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","2023-12-12 17:45:11.752076: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n","To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n","2023-12-12 17:45:12.943254: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n","Collecting pt-core-news-sm==3.6.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.6.0/pt_core_news_sm-3.6.0-py3-none-any.whl (13.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.7.0,>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.6.0) (3.6.1)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.0.9)\n","Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (8.1.12)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.10)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.9.0)\n","Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.10.3)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (4.66.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.23.5)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (1.10.13)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.1.2)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (23.2)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.3.0)\n","Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (4.5.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2023.11.17)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (8.1.7)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.7.0,>=3.6.0->pt-core-news-sm==3.6.0) (2.1.3)\n","Installing collected packages: pt-core-news-sm\n","Successfully installed pt-core-news-sm-3.6.0\n","\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n","\u001b[0m\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('pt_core_news_sm')\n"]}],"source":["!python -m pip install --upgrade pip\n","!pip install seqeval\n","!pip install -U sklearn_crfsuite\n","!pip install scikit-learn==1.3.2\n","\n","!python -m spacy download pt_core_news_sm"]},{"cell_type":"code","source":["import os\n","import numpy as np\n","\n","from sklearn_crfsuite import CRF\n","from seqeval.metrics import classification_report"],"metadata":{"id":"48UaJarT7rhN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/messias077/ner_pt/main/data/corpora/le_ner/train.conll\n","!wget https://raw.githubusercontent.com/messias077/ner_pt/main/data/corpora/le_ner/test.conll"],"metadata":{"id":"hPP-n9xN76Jz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702403129197,"user_tz":180,"elapsed":684,"user":{"displayName":"Mateus Merçon","userId":"05028490932371476290"}},"outputId":"e485f5a7-d714-4c47-c2aa-8e486f410955"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-12-12 17:45:28--  https://raw.githubusercontent.com/messias077/ner_pt/main/data/corpora/le_ner/train.conll\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2142199 (2.0M) [text/plain]\n","Saving to: ‘train.conll’\n","\n","train.conll         100%[===================>]   2.04M  --.-KB/s    in 0.08s   \n","\n","2023-12-12 17:45:28 (27.0 MB/s) - ‘train.conll’ saved [2142199/2142199]\n","\n","--2023-12-12 17:45:28--  https://raw.githubusercontent.com/messias077/ner_pt/main/data/corpora/le_ner/test.conll\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 438441 (428K) [text/plain]\n","Saving to: ‘test.conll’\n","\n","test.conll          100%[===================>] 428.17K  --.-KB/s    in 0.05s   \n","\n","2023-12-12 17:45:28 (7.77 MB/s) - ‘test.conll’ saved [438441/438441]\n","\n"]}]},{"cell_type":"code","source":["!wget https://raw.githubusercontent.com/ulysses-camara/ulysses-ner-br/main/annotated-corpora/PL_corpus_conll/pl_corpus_categorias/train.txt\n","!wget https://raw.githubusercontent.com/ulysses-camara/ulysses-ner-br/main/annotated-corpora/PL_corpus_conll/pl_corpus_categorias/test.txt"],"metadata":{"id":"p3k-qVQZH_iT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702403129873,"user_tz":180,"elapsed":678,"user":{"displayName":"Mateus Merçon","userId":"05028490932371476290"}},"outputId":"3cbfa48f-b26f-480f-bbec-6edf7c66929c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["--2023-12-12 17:45:28--  https://raw.githubusercontent.com/ulysses-camara/ulysses-ner-br/main/annotated-corpora/PL_corpus_conll/pl_corpus_categorias/train.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 779304 (761K) [text/plain]\n","Saving to: ‘train.txt’\n","\n","train.txt           100%[===================>] 761.04K  --.-KB/s    in 0.06s   \n","\n","2023-12-12 17:45:29 (12.0 MB/s) - ‘train.txt’ saved [779304/779304]\n","\n","--2023-12-12 17:45:29--  https://raw.githubusercontent.com/ulysses-camara/ulysses-ner-br/main/annotated-corpora/PL_corpus_conll/pl_corpus_categorias/test.txt\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 185614 (181K) [text/plain]\n","Saving to: ‘test.txt’\n","\n","test.txt            100%[===================>] 181.26K  --.-KB/s    in 0.04s   \n","\n","2023-12-12 17:45:29 (4.64 MB/s) - ‘test.txt’ saved [185614/185614]\n","\n"]}]},{"cell_type":"markdown","source":["## Função para leitura da base de dados no padrão BIO"],"metadata":{"id":"pK8x3LXd8BJU"}},{"cell_type":"code","source":["def read_corpus_file(corpus_file, delimiter='\\t', ner_column=1):\n","    with open(corpus_file, encoding='utf-8') as file:\n","        lines = file.readlines()\n","    data = []\n","    words = []\n","    tags = []\n","    for line in lines:\n","        line = line.replace('\\n', '')\n","        if line != '':\n","            if delimiter in line:\n","                fragments = line.split(delimiter)\n","                words.append(fragments[0])\n","                tags.append(fragments[ner_column])\n","        else:\n","            if len(words) > 1:\n","                data.append((words, tags))\n","            words = []\n","            tags = []\n","    return data"],"metadata":{"id":"1r7G62h77-pS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# corpus_name = 'le_ner'\n","corpus_name = 'ulysses_ner'\n","\n","report_dir = 'report/'\n","\n","train_file = None\n","test_file = None\n","\n","id_ner = 1\n","delimiter = ' '\n","\n","if corpus_name == 'le_ner':\n","  train_file = '/content/train.conll'\n","  test_file = '/content/test.conll'\n","elif corpus_name == 'ulysses_ner':\n","  train_file = '/content/train.txt'\n","  test_file = '/content/test.txt'\n","\n","print(f'\\nCorpus: {corpus_name}')\n","\n","report_dir = os.path.join(report_dir, corpus_name)\n","\n","os.makedirs(report_dir, exist_ok=True)\n","\n","train_data = read_corpus_file(train_file, delimiter=delimiter, ner_column=id_ner)\n","test_data = read_corpus_file(test_file, delimiter=delimiter, ner_column=id_ner)\n","\n","print(f'\\nTrain data: {len(train_data)}')\n","print(f'Test data: {len(test_data)}')\n","\n","test_data_original = np.array(test_data, dtype=object)"],"metadata":{"id":"JgJM7-9z8GdK","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702403298681,"user_tz":180,"elapsed":270,"user":{"displayName":"Mateus Merçon","userId":"05028490932371476290"}},"outputId":"37f53350-b0e6-41fd-b508-def8fec172e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Corpus: ulysses_ner\n","\n","Train data: 2269\n","Test data: 523\n"]}]},{"cell_type":"code","source":["train_data[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-AG4Yri0Wr4b","executionInfo":{"status":"ok","timestamp":1702403298941,"user_tz":180,"elapsed":3,"user":{"displayName":"Mateus Merçon","userId":"05028490932371476290"}},"outputId":"0718b78f-ef77-4f77-ef48-5cdd9da5dfc4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['Sala', 'das', 'Sessões', ',', 'em', 'de', 'de', '2019', '.'],\n"," ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATA', 'O'])"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","source":["## Função que executa o pré-processamento do corpus usando a ferramenta Spacy"],"metadata":{"id":"7ValkLyP8OXK"}},{"cell_type":"code","source":["import spacy\n","\n","def data_preprocessing(data):\n","    nlp = spacy.load(name='pt_core_news_sm',\n","                     disable=['parser', 'ner', 'lemmatizer', 'textcat'])\n","    preprocessed_data = []\n","    for d in data:\n","        sentence = ' '.join(d[0])\n","        doc = nlp(sentence)\n","        pos_tags = [t.pos_ for t in doc]\n","        preprocessed_data.append((d[0], pos_tags, d[1]))\n","    return preprocessed_data"],"metadata":{"id":"rAKyUmPa8K7q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = data_preprocessing(train_data)\n","\n","test_data = data_preprocessing(test_data)"],"metadata":{"id":"NZMHKGET8Vgp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KVwOPdvoYM4y","executionInfo":{"status":"ok","timestamp":1702403315035,"user_tz":180,"elapsed":4,"user":{"displayName":"Mateus Merçon","userId":"05028490932371476290"}},"outputId":"039618da-52e2-4c24-bd65-8491b92f7bb7"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(['Sala', 'das', 'Sessões', ',', 'em', 'de', 'de', '2019', '.'],\n"," ['PROPN', 'ADP', 'PROPN', 'PUNCT', 'ADP', 'ADP', 'ADP', 'NUM', 'PUNCT'],\n"," ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATA', 'O'])"]},"metadata":{},"execution_count":27}]},{"cell_type":"markdown","source":["## Funções usadas para extrair as features dos tokens e de seus vizinhos."],"metadata":{"id":"5hcAEkI08Yo0"}},{"cell_type":"code","source":["def extract_sent_features(sentence):\n","    return [extract_features(sentence, i) for i in range(len(sentence))]\n","\n","\n","def extract_labels(sentence):\n","    return [label for _, _, label in sentence]\n","\n","\n","def extract_features(sentence, i):\n","    word = sentence[i][0]\n","    postag = sentence[i][1]\n","    features = {\n","        'bias': 1.0,\n","        'word.lower()': word.lower(),\n","        'word[-3:]': word[-3:],\n","        'word[-2:]': word[-2:],\n","        'word.isupper()': word.isupper(),\n","        'word.istitle()': word.istitle(),\n","        'word.isdigit()': word.isdigit(),\n","        'postag': postag,\n","        'postag[:2]': postag[:2],\n","        'word.islower()': word.islower(),\n","        'word[0].isupper()': word[0].isupper(),\n","        'word[0].islower()': word[0].islower(),\n","        'not word[0].isalnum()': not word[0].isalnum(),\n","        'not word.isalnum()': not word.isalnum(),\n","        'word.isalpha()': word.isalpha()\n","    }\n","    if i > 0:\n","        word1 = sentence[i - 1][0]\n","        postag1 = sentence[i - 1][1]\n","        features.update({\n","            '-1:word.lower()': word1.lower(),\n","            '-1:word.istitle()': word1.istitle(),\n","            '-1:word.isupper()': word1.isupper(),\n","            '-1:postag': postag1,\n","            '-1:postag[:2]': postag1[:2],\n","            '-1:word.islower()': word1.islower()\n","        })\n","    else:\n","        features['BOS'] = True # BOS = Begin of Sentence\n","    if i > 1:\n","        word1 = sentence[i - 2][0]\n","        postag1 = sentence[i - 2][1]\n","        features.update({\n","            '-2:word.lower()': word1.lower(),\n","            '-2:word.istitle()': word1.istitle(),\n","            '-2:word.isupper()': word1.isupper(),\n","            '-2:postag': postag1,\n","            '-2:postag[:2]': postag1[:2],\n","            '-2:word.islower()': word1.islower()\n","        })\n","    if i < len(sentence) - 1:\n","        word1 = sentence[i + 1][0]\n","        postag1 = sentence[i + 1][1]\n","        features.update({\n","            '+1:word.lower()': word1.lower(),\n","            '+1:word.istitle()': word1.istitle(),\n","            '+1:word.isupper()': word1.isupper(),\n","            '+1:postag': postag1,\n","            '+1:postag[:2]': postag1[:2],\n","            '+1:word.islower()': word1.islower()\n","        })\n","    else:\n","        features['EOS'] = True # EOS = End of Sentence\n","    if i < len(sentence) - 2:\n","        word1 = sentence[i + 2][0]\n","        postag1 = sentence[i + 2][1]\n","        features.update({\n","            '+2:word.lower()': word1.lower(),\n","            '+2:word.istitle()': word1.istitle(),\n","            '+2:word.isupper()': word1.isupper(),\n","            '+2:postag': postag1,\n","            '+2:postag[:2]': postag1[:2],\n","            '+2:word.islower()': word1.islower()\n","        })\n","    return features\n","\n","\n","def convert_data(data):\n","    sentences = []\n","    for d in data:\n","        sentences.append(list(zip(d[0], d[1], d[2])))\n","    x_data = [extract_sent_features(s) for s in sentences]\n","    y_data = [extract_labels(s) for s in sentences]\n","    return x_data, y_data"],"metadata":{"id":"vRvHiHzO8gj7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train, y_train = convert_data(train_data)\n","\n","X_test, y_test = convert_data(test_data)"],"metadata":{"id":"iGcxsxO78kYj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(f'\\nExample features: {X_train[0]}')\n","\n","print(f'\\nLabel: {y_train[0]}')"],"metadata":{"id":"cKwDtpC48nmS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702403316195,"user_tz":180,"elapsed":4,"user":{"displayName":"Mateus Merçon","userId":"05028490932371476290"}},"outputId":"7a2bc636-c19d-40da-c9d3-f853d20b09c6"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Example features: [{'bias': 1.0, 'word.lower()': 'sala', 'word[-3:]': 'ala', 'word[-2:]': 'la', 'word.isupper()': False, 'word.istitle()': True, 'word.isdigit()': False, 'postag': 'PROPN', 'postag[:2]': 'PR', 'word.islower()': False, 'word[0].isupper()': True, 'word[0].islower()': False, 'not word[0].isalnum()': False, 'not word.isalnum()': False, 'word.isalpha()': True, 'BOS': True, '+1:word.lower()': 'das', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADP', '+1:postag[:2]': 'AD', '+1:word.islower()': True, '+2:word.lower()': 'sessões', '+2:word.istitle()': True, '+2:word.isupper()': False, '+2:postag': 'PROPN', '+2:postag[:2]': 'PR', '+2:word.islower()': False}, {'bias': 1.0, 'word.lower()': 'das', 'word[-3:]': 'das', 'word[-2:]': 'as', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADP', 'postag[:2]': 'AD', 'word.islower()': True, 'word[0].isupper()': False, 'word[0].islower()': True, 'not word[0].isalnum()': False, 'not word.isalnum()': False, 'word.isalpha()': True, '-1:word.lower()': 'sala', '-1:word.istitle()': True, '-1:word.isupper()': False, '-1:postag': 'PROPN', '-1:postag[:2]': 'PR', '-1:word.islower()': False, '+1:word.lower()': 'sessões', '+1:word.istitle()': True, '+1:word.isupper()': False, '+1:postag': 'PROPN', '+1:postag[:2]': 'PR', '+1:word.islower()': False, '+2:word.lower()': ',', '+2:word.istitle()': False, '+2:word.isupper()': False, '+2:postag': 'PUNCT', '+2:postag[:2]': 'PU', '+2:word.islower()': False}, {'bias': 1.0, 'word.lower()': 'sessões', 'word[-3:]': 'ões', 'word[-2:]': 'es', 'word.isupper()': False, 'word.istitle()': True, 'word.isdigit()': False, 'postag': 'PROPN', 'postag[:2]': 'PR', 'word.islower()': False, 'word[0].isupper()': True, 'word[0].islower()': False, 'not word[0].isalnum()': False, 'not word.isalnum()': False, 'word.isalpha()': True, '-1:word.lower()': 'das', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADP', '-1:postag[:2]': 'AD', '-1:word.islower()': True, '-2:word.lower()': 'sala', '-2:word.istitle()': True, '-2:word.isupper()': False, '-2:postag': 'PROPN', '-2:postag[:2]': 'PR', '-2:word.islower()': False, '+1:word.lower()': ',', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'PUNCT', '+1:postag[:2]': 'PU', '+1:word.islower()': False, '+2:word.lower()': 'em', '+2:word.istitle()': False, '+2:word.isupper()': False, '+2:postag': 'ADP', '+2:postag[:2]': 'AD', '+2:word.islower()': True}, {'bias': 1.0, 'word.lower()': ',', 'word[-3:]': ',', 'word[-2:]': ',', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'PUNCT', 'postag[:2]': 'PU', 'word.islower()': False, 'word[0].isupper()': False, 'word[0].islower()': False, 'not word[0].isalnum()': True, 'not word.isalnum()': True, 'word.isalpha()': False, '-1:word.lower()': 'sessões', '-1:word.istitle()': True, '-1:word.isupper()': False, '-1:postag': 'PROPN', '-1:postag[:2]': 'PR', '-1:word.islower()': False, '-2:word.lower()': 'das', '-2:word.istitle()': False, '-2:word.isupper()': False, '-2:postag': 'ADP', '-2:postag[:2]': 'AD', '-2:word.islower()': True, '+1:word.lower()': 'em', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADP', '+1:postag[:2]': 'AD', '+1:word.islower()': True, '+2:word.lower()': 'de', '+2:word.istitle()': False, '+2:word.isupper()': False, '+2:postag': 'ADP', '+2:postag[:2]': 'AD', '+2:word.islower()': True}, {'bias': 1.0, 'word.lower()': 'em', 'word[-3:]': 'em', 'word[-2:]': 'em', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADP', 'postag[:2]': 'AD', 'word.islower()': True, 'word[0].isupper()': False, 'word[0].islower()': True, 'not word[0].isalnum()': False, 'not word.isalnum()': False, 'word.isalpha()': True, '-1:word.lower()': ',', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'PUNCT', '-1:postag[:2]': 'PU', '-1:word.islower()': False, '-2:word.lower()': 'sessões', '-2:word.istitle()': True, '-2:word.isupper()': False, '-2:postag': 'PROPN', '-2:postag[:2]': 'PR', '-2:word.islower()': False, '+1:word.lower()': 'de', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADP', '+1:postag[:2]': 'AD', '+1:word.islower()': True, '+2:word.lower()': 'de', '+2:word.istitle()': False, '+2:word.isupper()': False, '+2:postag': 'ADP', '+2:postag[:2]': 'AD', '+2:word.islower()': True}, {'bias': 1.0, 'word.lower()': 'de', 'word[-3:]': 'de', 'word[-2:]': 'de', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADP', 'postag[:2]': 'AD', 'word.islower()': True, 'word[0].isupper()': False, 'word[0].islower()': True, 'not word[0].isalnum()': False, 'not word.isalnum()': False, 'word.isalpha()': True, '-1:word.lower()': 'em', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADP', '-1:postag[:2]': 'AD', '-1:word.islower()': True, '-2:word.lower()': ',', '-2:word.istitle()': False, '-2:word.isupper()': False, '-2:postag': 'PUNCT', '-2:postag[:2]': 'PU', '-2:word.islower()': False, '+1:word.lower()': 'de', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'ADP', '+1:postag[:2]': 'AD', '+1:word.islower()': True, '+2:word.lower()': '2019', '+2:word.istitle()': False, '+2:word.isupper()': False, '+2:postag': 'NUM', '+2:postag[:2]': 'NU', '+2:word.islower()': False}, {'bias': 1.0, 'word.lower()': 'de', 'word[-3:]': 'de', 'word[-2:]': 'de', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'ADP', 'postag[:2]': 'AD', 'word.islower()': True, 'word[0].isupper()': False, 'word[0].islower()': True, 'not word[0].isalnum()': False, 'not word.isalnum()': False, 'word.isalpha()': True, '-1:word.lower()': 'de', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADP', '-1:postag[:2]': 'AD', '-1:word.islower()': True, '-2:word.lower()': 'em', '-2:word.istitle()': False, '-2:word.isupper()': False, '-2:postag': 'ADP', '-2:postag[:2]': 'AD', '-2:word.islower()': True, '+1:word.lower()': '2019', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'NUM', '+1:postag[:2]': 'NU', '+1:word.islower()': False, '+2:word.lower()': '.', '+2:word.istitle()': False, '+2:word.isupper()': False, '+2:postag': 'PUNCT', '+2:postag[:2]': 'PU', '+2:word.islower()': False}, {'bias': 1.0, 'word.lower()': '2019', 'word[-3:]': '019', 'word[-2:]': '19', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': True, 'postag': 'NUM', 'postag[:2]': 'NU', 'word.islower()': False, 'word[0].isupper()': False, 'word[0].islower()': False, 'not word[0].isalnum()': False, 'not word.isalnum()': False, 'word.isalpha()': False, '-1:word.lower()': 'de', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'ADP', '-1:postag[:2]': 'AD', '-1:word.islower()': True, '-2:word.lower()': 'de', '-2:word.istitle()': False, '-2:word.isupper()': False, '-2:postag': 'ADP', '-2:postag[:2]': 'AD', '-2:word.islower()': True, '+1:word.lower()': '.', '+1:word.istitle()': False, '+1:word.isupper()': False, '+1:postag': 'PUNCT', '+1:postag[:2]': 'PU', '+1:word.islower()': False}, {'bias': 1.0, 'word.lower()': '.', 'word[-3:]': '.', 'word[-2:]': '.', 'word.isupper()': False, 'word.istitle()': False, 'word.isdigit()': False, 'postag': 'PUNCT', 'postag[:2]': 'PU', 'word.islower()': False, 'word[0].isupper()': False, 'word[0].islower()': False, 'not word[0].isalnum()': True, 'not word.isalnum()': True, 'word.isalpha()': False, '-1:word.lower()': '2019', '-1:word.istitle()': False, '-1:word.isupper()': False, '-1:postag': 'NUM', '-1:postag[:2]': 'NU', '-1:word.islower()': False, '-2:word.lower()': 'de', '-2:word.istitle()': False, '-2:word.isupper()': False, '-2:postag': 'ADP', '-2:postag[:2]': 'AD', '-2:word.islower()': True, 'EOS': True}]\n","\n","Label: ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-DATA', 'O']\n"]}]},{"cell_type":"code","source":["crf = CRF(max_iterations=100, c1=0.1, c2=0.1, all_possible_transitions=True)"],"metadata":{"id":"4hCHY0F08sr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["try:\n","  crf.fit(X_train, y_train)\n","except AttributeError:\n","  pass"],"metadata":{"id":"RQVqdK6l87wC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_pred = crf.predict(X_test)"],"metadata":{"id":"9vlds6NBhjEf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["report = classification_report(y_test, y_pred)\n","\n","print(report)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3YlEN-vNh6Lo","executionInfo":{"status":"ok","timestamp":1702403359931,"user_tz":180,"elapsed":405,"user":{"displayName":"Mateus Merçon","userId":"05028490932371476290"}},"outputId":"8a4e4152-e6ec-47aa-b5cc-6dd5403ac555"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","        DATA       0.96      0.94      0.95        98\n","      EVENTO       1.00      0.22      0.36         9\n","  FUNDAMENTO       0.85      0.85      0.85       124\n","       LOCAL       0.81      0.72      0.76       101\n"," ORGANIZACAO       0.76      0.72      0.74        94\n","      PESSOA       0.92      0.81      0.86       119\n","PRODUTODELEI       0.73      0.65      0.69        54\n","\n","   micro avg       0.85      0.79      0.82       599\n","   macro avg       0.86      0.70      0.74       599\n","weighted avg       0.85      0.79      0.81       599\n","\n"]}]},{"cell_type":"code","source":["report_file = os.path.join(report_dir, f'pln-trabalho-02-{corpus_name}.csv')\n","with open(report_file, 'w', encoding='utf-8') as f:\n","    f.write(report)"],"metadata":{"id":"c-RUHG1gIMdD"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def extract_ner(x, y, exclude=None, is_bio=False):\n","    if len(x) != len(y):\n","        print(\"\\nERROR: 'x' and 'y' must be the same size.\")\n","        return None\n","    if type(exclude) is not list:\n","        exclude = []  # Guarda os tokens que serão excluídos do resultado\n","    extracted_ners = []  # Guarda dicionários com as entidades nomeadas filtradas/agrupadas\n","    for i in range(len(y)):\n","        ind_last_token = len(y[i]) - 1\n","        j = 0\n","        same_entity = []  # Guarda os índices dos tokens vizinhos que pertencem à mesma entidade nomeada\n","        ners = {}  # Guarda o índice do token (como chave) e uma lista de tokens vizinhos que pertencem à mesma entidade\n","        has_began = False  # Indica se um label começou com 'B-', no caso do formato BIO\n","        # Percorre cada um dos tipos de tokens da sentença e, se houver, verifica se o proximo tipo de token é igual\n","        while j <= ind_last_token:\n","            if y[i][j] not in exclude:\n","                if j not in same_entity:\n","                    same_entity.append(j)\n","                    if is_bio and len(y[i][j]) >= 2 and y[i][j][:2].upper() == 'B-':  # Se é do formato BIO e é início\n","                        has_began = True\n","                if j + 1 <= ind_last_token:\n","                    if has_began and len(y[i][j + 1]) >= 2 and y[i][j + 1][:2].upper() == 'I-' \\\n","                            and y[i][j][2:] == y[i][j + 1][2:]:\n","                        same_entity.append(j + 1)\n","                    elif not is_bio and y[i][j] == y[i][j + 1]:\n","                        same_entity.append(j + 1)\n","                    else:\n","                        ners[j] = same_entity\n","                        same_entity = []\n","                        has_began = False\n","                else:\n","                    ners[j] = same_entity\n","                    has_began = False\n","            j += 1\n","        # Processa as ners extraidas da sentença desta iteração\n","        if ners:\n","            sent = x[i]\n","            ners_aux = []\n","            for ind_token, filtered_tokens in ners.items():\n","                ner = ''\n","                for t in filtered_tokens:\n","                    ner += sent[t] + ' '\n","                # Trata o caso do formato BIO e retira os 'B-' e 'I-' dos nomes dos labels\n","                if is_bio and len(y[i][ind_token]) >= 2:\n","                    label = y[i][ind_token][2:]\n","                else:\n","                    label = y[i][ind_token]\n","                ners_aux.append((ner.strip(), label))\n","            extracted_ners.append(ners_aux)\n","        else:\n","            extracted_ners.append([])  # Para manter a ordem das sentenças, caso não seja extraida nenhuma ner\n","    return extracted_ners"],"metadata":{"id":"GBGCw6xNh7Ng"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ner_ext_test = extract_ner(test_data_original[:, 0],test_data_original[:, 1], exclude=['O'], is_bio=True)\n","\n","ner_ext_pred = extract_ner(test_data_original[:, 0], y_pred, exclude=['O'], is_bio=True)"],"metadata":{"id":"zT0EUwfkmFWb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["ner_ext_test[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nyO8De9mZJi","executionInfo":{"status":"ok","timestamp":1702403360422,"user_tz":180,"elapsed":7,"user":{"displayName":"Mateus Merçon","userId":"05028490932371476290"}},"outputId":"15b44d6b-c04d-49ab-e60b-42b0efdf3ff4"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('art . 19 , da Lei n ° 6.001 , de 19 de dezembro de 1973', 'FUNDAMENTO')]"]},"metadata":{},"execution_count":38}]},{"cell_type":"code","source":["ner_ext_pred[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"umcHawyfnh6S","executionInfo":{"status":"ok","timestamp":1702403360422,"user_tz":180,"elapsed":6,"user":{"displayName":"Mateus Merçon","userId":"05028490932371476290"}},"outputId":"9e8b3ddf-953b-405e-9486-6662addb437e"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[('art . 19 , da Lei n ° 6.001 , de 19 de dezembro de 1973', 'FUNDAMENTO')]"]},"metadata":{},"execution_count":39}]}]}